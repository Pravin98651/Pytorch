{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ✅ **1. `.view()`**\n",
        "\n",
        "### 🔹 Description:\n",
        "\n",
        "* Changes the **shape** of the tensor **without copying the data**.\n",
        "* Only works on **contiguous** tensors (data must be laid out linearly in memory).\n",
        "\n",
        "### ❗ If the tensor is **not contiguous**, `.view()` will raise an error:\n",
        "\n",
        "```python\n",
        "RuntimeError: view size is not compatible with input tensor's size and stride...\n",
        "```\n",
        "\n",
        "### ✅ Use `.view()` when:\n",
        "\n",
        "* You **know** the tensor is **contiguous** (e.g., freshly created or `.contiguous()` was called).\n",
        "* You want to **avoid unnecessary memory copies** for performance reasons.\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ **2. `.reshape()`**\n",
        "\n",
        "### 🔹 Description:\n",
        "\n",
        "* Changes the **shape** of the tensor.\n",
        "* Works on **both contiguous and non-contiguous** tensors.\n",
        "* Will **copy memory** if required to make the reshape possible.\n",
        "\n",
        "### ✅ Use `.reshape()` when:\n",
        "\n",
        "* You’re not sure whether the tensor is contiguous.\n",
        "* You want a **safer and more flexible** operation.\n",
        "* You’re okay with a **possible memory copy** for convenience.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧪 Example Comparison:\n",
        "\n",
        "```python\n",
        "x = torch.randn(2, 3, 4)\n",
        "x_transposed = x.permute(1, 0, 2)  # non-contiguous\n",
        "\n",
        "x_transposed.view(6, 4)       # ❌ RuntimeError\n",
        "x_transposed.contiguous().view(6, 4)  # ✅ Works\n",
        "x_transposed.reshape(6, 4)    # ✅ Works (auto-handles contiguity)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 📊 Summary Table\n",
        "\n",
        "| Feature              | `.view()`                      | `.reshape()`                    |\n",
        "| -------------------- | ------------------------------ | ------------------------------- |\n",
        "| Requires contiguous? | ✅ Yes                          | ❌ No                            |\n",
        "| Can copy memory?     | ❌ No                           | ✅ Yes (if needed)               |\n",
        "| Safe for any tensor? | ❌ No                           | ✅ Yes                           |\n",
        "| Performance          | ⚡ Faster (no copy)             | Slightly slower (may copy)      |\n",
        "| Recommended when     | You need speed and know layout | You need flexibility and safety |\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Best Practice\n",
        "\n",
        "> 🔹 Use `.view()` when you're sure the tensor is **contiguous** (e.g., after `.contiguous()`).\n",
        "> 🔹 Use `.reshape()` for **general-purpose** reshaping, especially with **transposed or permuted tensors**.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R8wkBojnkg5w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Evphw4z5dg9M"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor=torch.arange(12)"
      ],
      "metadata": {
        "id": "DQO6oIgvdt94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_tensor_view=tensor.view(2,6)\n",
        "reshaped_tensor_reshape=tensor.reshape(2,6)\n",
        "print(reshaped_tensor_view)\n",
        "print(reshaped_tensor_reshape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiFpIDiid1w8",
        "outputId": "f5d2fcb3-272b-4f50-874c-cd614c6b62bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2,  3,  4,  5],\n",
            "        [ 6,  7,  8,  9, 10, 11]])\n",
            "tensor([[ 0,  1,  2,  3,  4,  5],\n",
            "        [ 6,  7,  8,  9, 10, 11]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.is_contiguous()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-ok-1bTeTfc",
        "outputId": "8f1efd30-1821-4b69-e91a-c54ed960d93d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inferred_shape= tensor.view(3,-1) #-1 pytorch will take the value by itself\n",
        "print(inferred_shape)\n",
        "print(inferred_shape.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVMoG26felxH",
        "outputId": "a5c2712d-c346-4136-e82e-176bb9365064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "torch.Size([3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor3d=torch.arange(24).reshape(2,3,4)\n",
        "print(tensor3d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zEAFY2teuLJ",
        "outputId": "0d76011a-4e04-424c-d661-8d173e42b723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0,  1,  2,  3],\n",
            "         [ 4,  5,  6,  7],\n",
            "         [ 8,  9, 10, 11]],\n",
            "\n",
            "        [[12, 13, 14, 15],\n",
            "         [16, 17, 18, 19],\n",
            "         [20, 21, 22, 23]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flattened=tensor3d.view(-1)\n",
        "print(flattened)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVbdEr1bgMZn",
        "outputId": "b4badd62-3b3d-4a2f-b3db-9518bf807964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22, 23])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flattened.is_contiguous()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzbyQRbugj5z",
        "outputId": "be0803b1-251a-4080-b427-fea7fbceff53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d=torch.arange(24).reshape(12,2)\n",
        "transposed_tensor=tensor2d.t()"
      ],
      "metadata": {
        "id": "vxg7pdDkg3c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transposed_tensor.is_contiguous()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IUAW4ECh2vp",
        "outputId": "5319482b-3059-4edb-ea9a-7421e5666736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transposed_tensor.view(6,4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "4yRhx5C1iCrw",
        "outputId": "3e1ceaa4-14f6-429c-8e83-6385f928f23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-055f1bd6e098>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransposed_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RX7rQr2AkKnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transposed_tensor.reshape(6,4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z-w4NGfiQCI",
        "outputId": "f26a896b-2cd8-4c1e-a868-92e5339e37c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  2,  4,  6],\n",
              "        [ 8, 10, 12, 14],\n",
              "        [16, 18, 20, 22],\n",
              "        [ 1,  3,  5,  7],\n",
              "        [ 9, 11, 13, 15],\n",
              "        [17, 19, 21, 23]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contiguous=transposed_tensor.contiguous()\n",
        "error=contiguous.view(6,4)"
      ],
      "metadata": {
        "id": "zN1lijnLiUFw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}